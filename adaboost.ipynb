{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(r\"./data/cardekho_imputated.csv\", index_col=[0])\n",
    "df=pd.read_csv('cardekho_imputated.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('car_name', axis=1, inplace=True)\n",
    "df.drop('brand', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features: 7\n",
      "cat_features: 4\n",
      "discrete_features: 2\n",
      "contious_features: 5\n"
     ]
    }
   ],
   "source": [
    "num_features= [features for features in df.columns if df[features].dtype !='O']\n",
    "print('num_features:', len(num_features))\n",
    "cat_features=[features for features in df.columns if df[features].dtype== 'O']\n",
    "print('cat_features:',len(cat_features))\n",
    "discrete_features=[feature for feature in num_features if len(df[feature].unique())<=25]\n",
    "print('discrete_features:',len(discrete_features))\n",
    "contious_features=[feature for feature in num_features if len(df[feature].unique())>25]\n",
    "print('contious_features:',len(contious_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['selling_price'], axis=1)\n",
    "y = df['selling_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "x['model']=le.fit_transform(df['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = x.select_dtypes(exclude=\"object\").columns\n",
    "one_hot_column=['seller_type','fuel_type','transmission_type']\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "std=StandardScaler()\n",
    "one_hot=OneHotEncoder(drop='first')\n",
    "preprocessor=ColumnTransformer([('Onehotencoder',one_hot,one_hot_column),('standard_scaler',std,num_features)],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.519714</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>1.247335</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-1.324259</td>\n",
       "      <td>-1.263352</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.225693</td>\n",
       "      <td>-0.343933</td>\n",
       "      <td>-0.690016</td>\n",
       "      <td>-0.192071</td>\n",
       "      <td>-0.554718</td>\n",
       "      <td>-0.432571</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.536377</td>\n",
       "      <td>1.647309</td>\n",
       "      <td>0.084924</td>\n",
       "      <td>-0.647583</td>\n",
       "      <td>-0.554718</td>\n",
       "      <td>-0.479113</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.519714</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>-0.360667</td>\n",
       "      <td>0.292211</td>\n",
       "      <td>-0.936610</td>\n",
       "      <td>-0.779312</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.666211</td>\n",
       "      <td>-0.012060</td>\n",
       "      <td>-0.496281</td>\n",
       "      <td>0.735736</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>-0.046502</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15406</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.508844</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>-0.869744</td>\n",
       "      <td>0.026096</td>\n",
       "      <td>-0.767733</td>\n",
       "      <td>-0.757204</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15407</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.556082</td>\n",
       "      <td>-1.339555</td>\n",
       "      <td>-0.728763</td>\n",
       "      <td>-0.527711</td>\n",
       "      <td>-0.216964</td>\n",
       "      <td>-0.220803</td>\n",
       "      <td>2.073444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15408</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.407551</td>\n",
       "      <td>-0.012060</td>\n",
       "      <td>0.220539</td>\n",
       "      <td>0.344954</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>0.068225</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15409</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.426247</td>\n",
       "      <td>-0.343933</td>\n",
       "      <td>72.541850</td>\n",
       "      <td>-0.887326</td>\n",
       "      <td>1.329794</td>\n",
       "      <td>0.917158</td>\n",
       "      <td>2.073444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15410</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.024131</td>\n",
       "      <td>-1.339555</td>\n",
       "      <td>-0.825631</td>\n",
       "      <td>-0.407839</td>\n",
       "      <td>0.020999</td>\n",
       "      <td>0.395884</td>\n",
       "      <td>-0.403022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15411 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6         7         8          9   \\\n",
       "0      1.0  0.0  0.0  0.0  0.0  1.0  1.0 -1.519714  0.983562   1.247335   \n",
       "1      1.0  0.0  0.0  0.0  0.0  1.0  1.0 -0.225693 -0.343933  -0.690016   \n",
       "2      1.0  0.0  0.0  0.0  0.0  1.0  1.0  1.536377  1.647309   0.084924   \n",
       "3      1.0  0.0  0.0  0.0  0.0  1.0  1.0 -1.519714  0.983562  -0.360667   \n",
       "4      0.0  0.0  1.0  0.0  0.0  0.0  1.0 -0.666211 -0.012060  -0.496281   \n",
       "...    ...  ...  ...  ...  ...  ...  ...       ...       ...        ...   \n",
       "15406  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.508844  0.983562  -0.869744   \n",
       "15407  0.0  0.0  0.0  0.0  0.0  1.0  1.0 -0.556082 -1.339555  -0.728763   \n",
       "15408  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.407551 -0.012060   0.220539   \n",
       "15409  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.426247 -0.343933  72.541850   \n",
       "15410  0.0  0.0  0.0  0.0  0.0  1.0  0.0 -1.024131 -1.339555  -0.825631   \n",
       "\n",
       "             10        11        12        13  \n",
       "0     -0.000276 -1.324259 -1.263352 -0.403022  \n",
       "1     -0.192071 -0.554718 -0.432571 -0.403022  \n",
       "2     -0.647583 -0.554718 -0.479113 -0.403022  \n",
       "3      0.292211 -0.936610 -0.779312 -0.403022  \n",
       "4      0.735736  0.022918 -0.046502 -0.403022  \n",
       "...         ...       ...       ...       ...  \n",
       "15406  0.026096 -0.767733 -0.757204 -0.403022  \n",
       "15407 -0.527711 -0.216964 -0.220803  2.073444  \n",
       "15408  0.344954  0.022918  0.068225 -0.403022  \n",
       "15409 -0.887326  1.329794  0.917158  2.073444  \n",
       "15410 -0.407839  0.020999  0.395884 -0.403022  \n",
       "\n",
       "[15411 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=preprocessor.fit_transform(x)\n",
    "x=pd.DataFrame(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12328, 14), (3083, 14))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL SELECTION AND TRAINING\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553855.6665\n",
      "- Mean Absolute Error: 268101.6071\n",
      "- R2 Score: 0.6218\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502543.5930\n",
      "- Mean Absolute Error: 279618.5794\n",
      "- R2 Score: 0.6645\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553855.6710\n",
      "- Mean Absolute Error: 268099.2226\n",
      "- R2 Score: 0.6218\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502542.6696\n",
      "- Mean Absolute Error: 279614.7461\n",
      "- R2 Score: 0.6645\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553856.3160\n",
      "- Mean Absolute Error: 268059.8015\n",
      "- R2 Score: 0.6218\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502533.8230\n",
      "- Mean Absolute Error: 279557.2169\n",
      "- R2 Score: 0.6645\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 325880.8558\n",
      "- Mean Absolute Error: 91392.3102\n",
      "- R2 Score: 0.8691\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 253138.6083\n",
      "- Mean Absolute Error: 112578.2436\n",
      "- R2 Score: 0.9149\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 20797.2352\n",
      "- Mean Absolute Error: 5164.8199\n",
      "- R2 Score: 0.9995\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 294943.0945\n",
      "- Mean Absolute Error: 122460.6363\n",
      "- R2 Score: 0.8844\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaboost classifier\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 787559.0221\n",
      "- Mean Absolute Error: 350244.4030\n",
      "- R2 Score: 0.2352\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 864673.1176\n",
      "- Mean Absolute Error: 377968.5777\n",
      "- R2 Score: 0.0068\n",
      "\n",
      "\n",
      "adaboost regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 453572.1620\n",
      "- Mean Absolute Error: 342793.9429\n",
      "- R2 Score: 0.7463\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 479835.3544\n",
      "- Mean Absolute Error: 358004.6697\n",
      "- R2 Score: 0.6941\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"adaboost classifier\": AdaBoostClassifier(),\n",
    "    \"adaboost regressor\": AdaBoostRegressor()\n",
    "   \n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(x_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    \n",
    "    #print('='*35)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETER TUNING\n",
    "adaboost_classifier_param={\n",
    "    \"n_estimators\":[50,60,70,80,90],\n",
    "    \"algorithm\":['SAMME','SAMME.R']\n",
    "}\n",
    "adaboost_regrressor_param={\"n_estimators\":[50,60,70,80],\n",
    "                           \"loss\":['linear',\"square\",\"exponential\"]}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 10 is smaller than n_iter=100. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................algorithm=SAMME, n_estimators=50; total time=   4.3s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=50; total time=   4.3s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=50; total time=   4.5s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=60; total time=   5.0s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=60; total time=   5.2s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=60; total time=   5.4s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=70; total time=   6.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=70; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................algorithm=SAMME, n_estimators=70; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................algorithm=SAMME, n_estimators=80; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................algorithm=SAMME, n_estimators=80; total time=   7.9s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=80; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................algorithm=SAMME, n_estimators=90; total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................algorithm=SAMME, n_estimators=90; total time=   8.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................algorithm=SAMME, n_estimators=90; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=50; total time=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=50; total time=  17.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=50; total time=  17.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=60; total time=  20.7s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=60; total time=  21.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=60; total time=  20.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=70; total time=  23.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=70; total time=  24.6s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=70; total time=  20.7s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=80; total time=  22.5s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=80; total time=  21.8s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=80; total time=  20.6s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=90; total time=  22.3s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=90; total time=  22.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=90; total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 12 is smaller than n_iter=100. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] END .......................loss=linear, n_estimators=60; total time=   0.4s\n",
      "[CV] END .......................loss=linear, n_estimators=60; total time=   0.4s\n",
      "[CV] END .......................loss=linear, n_estimators=50; total time=   0.5s\n",
      "[CV] END .......................loss=linear, n_estimators=50; total time=   0.5s\n",
      "[CV] END .......................loss=linear, n_estimators=50; total time=   0.5s\n",
      "[CV] END .......................loss=linear, n_estimators=60; total time=   0.6s\n",
      "[CV] END .......................loss=linear, n_estimators=70; total time=   0.5s\n",
      "[CV] END .......................loss=linear, n_estimators=70; total time=   0.4s\n",
      "[CV] END .......................loss=linear, n_estimators=70; total time=   0.7s\n",
      "[CV] END .......................loss=linear, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................loss=linear, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................loss=square, n_estimators=50; total time=   0.4s\n",
      "[CV] END .......................loss=square, n_estimators=50; total time=   0.5s\n",
      "[CV] END .......................loss=square, n_estimators=50; total time=   0.5s\n",
      "[CV] END .......................loss=linear, n_estimators=80; total time=   0.7s\n",
      "[CV] END .......................loss=square, n_estimators=60; total time=   0.5s\n",
      "[CV] END .......................loss=square, n_estimators=60; total time=   0.5s\n",
      "[CV] END .......................loss=square, n_estimators=60; total time=   0.5s\n",
      "[CV] END .......................loss=square, n_estimators=70; total time=   0.6s\n",
      "[CV] END .......................loss=square, n_estimators=70; total time=   0.5s\n",
      "[CV] END .......................loss=square, n_estimators=70; total time=   0.6s\n",
      "[CV] END .......................loss=square, n_estimators=80; total time=   0.6s\n",
      "[CV] END .......................loss=square, n_estimators=80; total time=   0.7s\n",
      "[CV] END ..................loss=exponential, n_estimators=50; total time=   0.5s\n",
      "[CV] END ..................loss=exponential, n_estimators=50; total time=   0.5s\n",
      "[CV] END ..................loss=exponential, n_estimators=50; total time=   0.5s\n",
      "[CV] END .......................loss=square, n_estimators=80; total time=   0.7s\n",
      "[CV] END ..................loss=exponential, n_estimators=60; total time=   0.6s\n",
      "[CV] END ..................loss=exponential, n_estimators=60; total time=   0.6s\n",
      "[CV] END ..................loss=exponential, n_estimators=60; total time=   0.5s\n",
      "[CV] END ..................loss=exponential, n_estimators=70; total time=   0.6s\n",
      "[CV] END ..................loss=exponential, n_estimators=70; total time=   0.6s\n",
      "[CV] END ..................loss=exponential, n_estimators=70; total time=   0.6s\n",
      "[CV] END ..................loss=exponential, n_estimators=80; total time=   0.6s\n",
      "[CV] END ..................loss=exponential, n_estimators=80; total time=   0.7s\n",
      "[CV] END ..................loss=exponential, n_estimators=80; total time=   0.6s\n",
      "---------------- Best Params for AdaBoost_classifier -------------------\n",
      "{'n_estimators': 50, 'algorithm': 'SAMME.R'}\n",
      "---------------- Best Params for AdaBoostRegressor -------------------\n",
      "{'n_estimators': 60, 'loss': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "randomcv_models = [ (\"AdaBoost_classifier\", AdaBoostClassifier(), adaboost_classifier_param),\n",
    "                   (\"AdaBoostRegressor\",AdaBoostRegressor(),adaboost_regrressor_param)\n",
    "                    ]\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_param = {}\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator=model,\n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=100,\n",
    "                                   cv=3,\n",
    "                                   verbose=2,\n",
    "                                   n_jobs=-1)\n",
    "    random.fit(x_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"---------------- Best Params for {model_name} -------------------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"AdaBoostclassifier\":AdaBoostClassifier(n_estimators=50,algorithm=\"SAMME.R\"),\n",
    "    \"Adaboost\":AdaBoostRegressor(n_estimators=60,loss='linear')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cybesama/Desktop/tryout/venv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostclassifier\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 787559.0221\n",
      "- Mean Absolute Error: 350244.4030\n",
      "- R2 Score: 0.2352\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 864673.1176\n",
      "- Mean Absolute Error: 377968.5777\n",
      "- R2 Score: 0.0068\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 484949.1129\n",
      "- Mean Absolute Error: 383125.4616\n",
      "- R2 Score: 0.7100\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 517172.1476\n",
      "- Mean Absolute Error: 399399.1442\n",
      "- R2 Score: 0.6447\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(x_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
